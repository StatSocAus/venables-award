[
  {
    "path": "examples/2021-08-30-tsibble/",
    "title": "Tidy temporal data frames and pipelines",
    "description": "An overview of tsibble's data structure and software design philosophy.",
    "author": [
      {
        "name": "Earo Wang",
        "url": "https://earo.me"
      }
    ],
    "date": "2021-08-30",
    "categories": [],
    "contents": "\nProfessor Di Cook is my PhD supervisor at Monash University, who is committed to open-source statistical software. Under her supervision, I have developed the tsibble package to facilitate temporal data analysis in a streamlined manner. This package received the 2019 John Chambers Statistical Software Award from the American Statistical Association.\nIntroduction\nMining temporal data for information is often inhibited by a multitude of formats: irregular or multiple time intervals, point event that needs aggregating, multiple observational units or repeated measurements on multiple individuals, heterogeneous data types. Time series models, in particular, the software supporting time series forecasting makes strict assumptions on the data to be provided, typically a matrix of numeric data with implicit time indices. Going from raw data to model-ready data is painful. This work presents a cohesive and conceptual framework for organizing and manipulating temporal data, which in turn flows into visualization and forecasting routines. Tidy data principles are extended to temporal data: (1) mapping the semantics of a dataset into its physical layout, (2) including an explicitly declared index variable representing time, (3) incorporating a “key” comprised of single or multiple variables to uniquely identify units over time. This tidy data representation most naturally supports thinking of operations on the data as building blocks, forming part of a “data pipeline” in time-based context. A sound data pipeline facilitates a fluent and fluid workflow for analyzing temporal data. The infrastructure of tidy temporal data has been implemented in the R package tsibble.\nData structure\nThe tsibble package provides a new data class of tbl_ts or tsibble to represent temporal data, structured in a layout as “tidy data”. A tsibble consists of a time index, key and other measured variables in a data-centric format, which is built on top of the tibble. This consequently gains the support for multiple column-wise atomic types and list-columns that can host a variety of objects. To coerce to a tsibble with as_tsibble(), one needs to declare the index and “key” as identifying variables. A valid tsibble requires distinct rows identified by the index and “key”. It is possible and recommended to check for identical entries of key and index before analysis using duplicates(). Duplicates signal a data quality issue, which would likely affect subsequent analyses and hence decision making. Users are encouraged to gaze at data early and reason the process of data cleaning. When the data meets the tsibble standard, it flows neatly into comprehensive exploration and forecasting.\nSoftware structure and design\nThe tidy data abstraction lays a pipeline infrastructure for data analysis modules of transformation, visualization and modelling. Each module communicates between each other, requiring tidy input, producing tidy output, chaining a series of operations together to accomplish the analytic tasks. The package concentrates on data architecture and manipulation tools to flatten the lumpy path from temporal data to an object that can be directly modelled in the tsibble framework, as well as transformed for visualization.\nSome general-purpose tidyverse verbs have been adapted for a tsibble in time domain, for example filter() picks observations, select() picks variables, and left_join() joins two tables. Several new tsibble-specific verbs have been developed for handling temporal transformation: (1) turn implicit missing values into explicit missing values with fill_gaps(); (2) collapse by time index to less granular interval with index_by(); (3) provides a shorthand for filtering time with filter_index(). The principle that underpins these verbs is a tsibble in and a tsibble out, and the first argument is always the data. Therefore one can compose a pipeline through the pipe operator %>% to write more graceful and expressive code.\nAttention has been paid to error handling. If a tsibble cannot be maintained in the output of a pipeline module, for example the index is dropped by aggregation, an error informs users of the problem and suggests alternatives. This avoids negatively surprising users and reminds them of time context.\nLastly, the tsibble infrastructure is extensible for new index types and new data subclasses, because it leverages S3 methods and classes in R. It provides a concrete foundation for a broad domain of downstream analytic tasks.\nA collection of packages including data sets, time series statistical methods, and forecasting, known as tidyverts, has been heavily developed surrounding the tsibble data structure. This ecosystem helps to build tidy time series workflow in a succinct, transparent and human-readable manner.\nOnline tutorials\nThe pkgdown site (http://tsibble.tidyverts.org) is the best place to get started with tsibble:\nVignette on Introduction to tsibble, describing the philosophy underlying tsibble’s data structure\nVignette on Handle implicit missingness with tsibble, demonstrating how to handle time gaps\nReference page to get a glimpse of current tsibble functionality\n\n\n\n",
    "preview": {},
    "last_modified": "2022-03-23T16:58:23+11:00",
    "input_file": {}
  },
  {
    "path": "examples/2021-08-19-making-your-own-cv-with-r-markdown/",
    "title": "Making your own CV with R Markdown",
    "description": "A brief introduction to the vitae package and tutorial for producing your own data driven CV.",
    "author": [
      {
        "name": "Mitchell O'Hara-Wild",
        "url": {}
      },
      {
        "name": "",
        "url": "https://www.mitchelloharawild.com/"
      },
      {
        "name": "",
        "url": {}
      },
      {
        "name": "",
        "url": {}
      },
      {
        "name": "",
        "url": {}
      }
    ],
    "date": "2021-08-19",
    "categories": [],
    "contents": "\nI find the process of maintaining my CV and customising its contents to suit each new work opportunity tedious. Since transitioning to write every blog, slide deck, and report with R Markdown, it was especially jarring to go back into my LaTeX editor and update the CV. It soon became abundantly clear to me that writing CVs in R Markdown is a great match, and so at the 2018 rOpenSci OzUnconf Rob Hyndman and I set to work on creating the vitae package and automating our CVs.\n\n\n\nThe vitae package provides a growing collection of popular LaTeX and HTML CV templates adapted for use with R Markdown. The CV template can be swapped out by simply changing the document’s output format, and it is also possible to generate your CV in multiple styles (HTML for your website, and PDF for print/email/forms).\nThe defining feature of the package is how functions are used in listing your education, experiences, accolades and publications. There are two functions for listing items in vitae: brief_entries() and detailed_entries(). Both functions accept external data sources that you would typically maintain independently of your CV. For instance, you may actively update your ORCID with education history. Using the rorcid package it is possible to automatically obtain your ORCID records as data and include them in your CV. You may also like to list the R packages you’ve developed using the pkgsearch package. Any source of data that can be read into a rectangular data format can be used with these functions. This includes local datasets that you directly created - maintaining a record of your professional experiences in a data format is not just useful for a CV, but can be used in generating your website too!\nPublications can be entered using the bibliography_entries() function, which reads in any bibliography format understood by pandoc (including BibTeX, YAML, and CSL-JSON). The entries are temporarily stored in a tibble, allowing you to filter and modify the entries as needed before including them in your CV.\nLastly, as vitae builds upon R Markdown you can additionally include any figures, tables, or other output you like. Some creative users have used leaflet to map their workplaces around the world, and others have visualised their abilities in programming languages with ggplot2.\nCreating a CV with vitae\nCreating the R Markdown document\nThe first step in creating your CV with R Markdown using vitae is to choose a template. A summary of available templates can be found here: https://pkg.mitchelloharawild.com/vitae/#templates. This choice can easily be changed later, by simply changing the output format of the R Markdown document. A boilerplate CV document using your chosen template can be created with:\n\n\n# Create a starter document for the awesomecv template\nrmarkdown::draft(\n  \"cv.Rmd\",                 # The name of the file to create\n  template = \"awesomecv\",   # The selected template\n  package = \"vitae\"         # The package, always \"vitae\"\n)\n\n\n\nAlternatively, if you use the RStudio IDE you can create the starter document by navigating to “File > New File > R Markdown…”. Then on the left panel select ‘From Template’, and on the right select your chosen vitae template.\nThis should give you a file that containing the appropriate YAML front matter and a body containing a brief demo of using the three *_entries() functions. A shortened preview of this file is given below.\n---\nname: Marie\nsurname: Curie\nposition: Professor\naddress: \"School of Physics & Chemistry, École Normale Supérieure\"\ntwitter: mariecurie\ndate: \"September 2021\"\noutput: vitae::awesomecv\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)\nlibrary(vitae)\n```\n\n# Education\n\n```{r}\nlibrary(tibble)\ntribble(\n  ~ Degree, ~ Year, ~ Institution, ~ Where,\n  \"Informal studies\", \"1889-91\", \"Flying University\", \"Warsaw, Poland\",\n  \"Master of Physics\", \"1893\", \"Sorbonne Université\", \"Paris, France\",\n  \"Master of Mathematics\", \"1894\", \"Sorbonne Université\", \"Paris, France\"\n) %>% \n  detailed_entries(Degree, Year, Institution, Where)\n```\n\nYou can try the template out by knitting this document ( Knit) or running:\n\n\nrmarkdown::render(\n  \"cv.Rmd\" # The path to your CV R Markdown document\n)\n\n\n\n\nMaking the CV your own\nFrom here it’s time to modify the template to start creating your own CV. A good place to start is with the YAML front matter, where you can set your name, position and contact information.\nBeing an R Markdown document, you can then start writing Markdown for the body of your CV. Perhaps start with a brief overview summary, or (as others have done) create a map that displays your relevant experiences.\nThe most prominent element of a CV is the listed entries that describe your past employment, education, and other evidence of your expertise. These types of entries can be created with one of three *_entries() functions which style the list to suit the selected template. data %>% brief_entries(what, when, with) creates a compact list, while data %>% detailed_entries(what, when, with, where, why) creates a larger more detailed list.\nThe data that is used to populate CV entries can come from any data source. It should be structured in a way where each row describes an entry, and the columns are passed into the appropriate field. Using data with this structure makes it easy to filter() for experiences relevant to your application. Many users (myself included) maintain a dataset for each type of entry that they like to include in the CV. While these datasets can grow over time as you add more experiences, your CV can be contain a reduced selection of this data to keep it concise and relevant.\nIf you have published academic work, you might also like to use the bibliography_entries() to create a list of your publications. This function accepts common bibliography file formats including BibTeX and CSL-JSON, and then creates a dataset from it. This dataset can then be filtered and modified as needed, and these changes will be reflected in the resulting bibliography list.\nFinally, render your document and admire your newly created CV made with R Markdown! Looking for inspiration? Check out what others have done with their vitae CV: https://pkg.mitchelloharawild.com/vitae/#examples-of-using-vitae\n\n\n\n",
    "preview": "examples/2021-08-19-making-your-own-cv-with-r-markdown/preview.png",
    "last_modified": "2022-03-23T16:58:23+11:00",
    "input_file": {},
    "preview_width": 640,
    "preview_height": 320
  }
]
